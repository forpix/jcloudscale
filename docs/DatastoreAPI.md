# Datastore API
The data store API is an JCloudScale extension that can be used to easily access different data stores through one API supporting all functions to create, read, update and delete data. Use it via the Maven dependency:

    <dependency>
       <groupId>jcloudscale</groupId>
       <artifactId>jcloudscale.datastorelib</artifactId>
       <version>0.4.0</version>
    </dependency>

## Configuration
The data stores used to manage the data are configured using a XML file, placed in the `META-INF` folder of the project. There is exactly one file
for each project named `datastores.xml`. A simple configuration may look as follows:

    <datastores>
      <datastore>
        <name>riak</name>
        <host>127.0.0.1</host>
            <port>8098</port>
            <dataunit>test</dataunit>
            <driver>at.ac.tuwien.infosys.jcloudscale.datastore.driver.riak.RiakDriver</driver>
        </datastore>
    </datastores>

A configuration file can contain the settings for multiple data stores. There are basically 5 options used to configure a data store:

|**Option** | **Example On** | **Description** |
| ------------- | ------------ | ----------- |
| name | riak | The name of the data store used as reference|
| host | 127.0.0.1 | The host of the data store|
| port | 8098 | The port used by the data store|
| dataunit | test | The name of the unit used to group data (table, bucket, ...)|
| driver | at.ac.tuwien.infosys.jcloudscale.datastore.driver.riak.RiakDriver | The driver used for data store communication|

As we can see, each data store requires a special driver used for communication. Actually the following drivers are supported:

|**Data Store**| **Driver**|
| ------------ | --------- |
| CouchDB | at.ac.tuwien.infosys.jcloudscale.datastore.driver.couchdb.CouchDBDriver|
| Riak | at.ac.tuwien.infosys.jcloudscale.datastore.driver.riak.RiakDriver|
| HBase | at.ac.tuwien.infosys.jcloudscale.datastore.driver.hbase.HbaseDriver|

New drivers can be created implementing the libraries `DatastoreDriver` interface.

## Mapping
Java objects are mapped to JSON or HBase by simply transforming each field of the object to a JSON field or a HBase Cell. Constants will be ignored and
are generally not mapped by the framework. To manage an object in a data store, it is necessary to add an identifier field using the libraries `@DatatoreId`
annotation. Identifiers can be managed using two different strategies, `AUTO` and `MANUAL`. The default option is `AUTO`, where the identifier is
generated by the framework. Using the `MANUAL` strategy requires the user to manually generate and set the identifier for the object.

In some cases it is necessary to use a different mapping for a special type of fields. In this case, custom type adapters can be implemented controlling the 
output of the mapping. To create a custom adapter it is necessary to implement the libraries `TypeAdapter` interface. An implementation might look like this:

    
    public class JsonGenderTypeAdapter implements TypeAdapter<Gender, JsonElement> {
    
       @Override
       public JsonElement serialize(Gender object, TypeMetadata<JsonElement> typeMetadata) {
           return new JsonPrimitive(object.toString());
       }
    
       @Override
       public Gender deserialize(JsonElement element, TypeMetadata<JsonElement> typeMetadata) {
           JsonPrimitive jsonPrimitive = (JsonPrimitive) element;
           if(!jsonPrimitive.isString()) {
               throw new DatastoreException("Invalid value for gender type.");
           }
           String value = jsonPrimitive.getAsString();
           return Gender.valueOf(value);
       }
    }

As we can see, there are actually two methods required for serializing and deserializing a specific type. The first method is used to convert a `Gender`
instance to a corresponding JsonElement. In our example, the enum is simply converted to its default string representation. For transforming `Gender` fields 
to HBase a separate type adapter is necessary. An example using the custom type adapter might look as follows:

    
    public class Person {
       @DatastoreId(strategy = IdStrategy.AUTO)
       private String id;  
       private String firstName;
       private String lastName;
       public enum Gender {
           MALE, FEMALE
       }
       @Adapters({
           @Adapter(targetClass # JsonElement.class, adapterClass JsonGenderTypeAdapter.class)
       })
       private Gender gender;
    }

## Usage
The different data stores are generally accessed using the `Datastore` interface. To get an instance of the corresponding implementation for a data store,
the frameworks `DataSource` annotation is used.

    
    public class Main {
       @DataSource(name = "couchdb")
       private static Datastore datastore;
    
       public static void main(String[] args) {
           Person person = new Person();
           ...
           datastore.save(person);
       }
    }

In the example above, the `DataSource` annotation is used to get an instance for the CouchDB data store, named `couchdb`. The name used in the annotation is 
the same used in the `datastores.xml` file.

You can use this annotation in your application, as well as in a cloud object:

    
    @CloudObject
    public class MyCO {
       
       @DataSource(name = "riak")
       private static Datastore datastore;

Using datastores in cloud objects has the inherent advantage that optimistic locking is used to ensure consistency between multiple physical hosts. That is, if you write to the same entity in a data store from different hosts in the cloud, the second (conflicting) update will lead to a `DataStoreException`, which you can catch and handle.

Another possibility to get an instance, without using annotations, is the DatastoreFactory:

    Datastore datastore = DatastoreFactory.getInstance().getDatastoreByName("couchdb");

Actually the following methods are provided by the interface:

|**Method**|**Description**|
| -------- | ------------- |
| `void save(Object object)` | Save the given object|
| `<T> T find(Class<T> objectClass, String id)` | Find the object of the given type with the given id|
| `void delete(Object object);` | Delete the given object|
|`void update(Object object);` | Update the given object|
|`<T> void migrate(Datastore to, Class<T> objectClass, String id);` | Migrate an object to another data store|
|`<T> void migrate(Datastore to, Class<T> objectClass, MigrationCallback<T> callback, String... ids);`| Migrate multiple objects to another data store|

A special feature is the possibility to migrate objects from one data store to another, without implementing any additional code. Therefore, the migrate methods can
be used to migrate single or multiple objects between data stores. In case of migrating multiple objects, a callback object can be passed to be called when all data
is migrated.

    
    public class PersonMigrationCallback implements MigrationCallback<Person> {
    
       final Logger logger = LoggerFactory.getLogger(this.getClass());
    
       public void onSuccess(List<Person> result) {
           logger.info("Successfully migrated {} person objects.", result.size());
       }
    
       public void onError() {
           logger.error("Error migrating person objects.");
       }
    }

An object implementing the callback interface has to provide two methods, one for a successful migration and another one if an error occurs. The first methods also 
gets a list of the migrated objects as parameter.

## External Libraries
A feature often required by clients is the integration of external libraries to use data store specific functions. To help the users with this task, a special feature 
for injecting third-party libraries can be used to create the instance and to establish the connection to the data store.

    <datastores>
       <datastore>
           <name>couchdb</name>
           <host>192.168.56.101</host>
           <port>5984</port>
           <dataunit>jcloudscale</dataunit>
           <driver>at.ac.tuwien.infosys.jcloudscale.datastore.driver.couchdb.CouchDBDriver</driver>
           <libs>
               <lib>
                   <lib-name>lightcouch</lib-name>
                   <lib-wrapper>
                   at.ac.tuwien.infosys.jcloudscale.datastore.ext.LightCouchWrapper
                   </lib-wrapper>
               </lib>
           </libs>
       </datastore>
    </datastores>

To inject instances of a third-party library it is necessary to extend the configuration in the `datastores.xml` file shown above. In the libs section of the data store an unbound
number of libraries can be added using the lib tag. The lib-name provided in the configuration is then used to get the entry for the corresponding library using the lib-wrapper 
to create an instance of the required class.

The external library can then be injected using the `DatastoreLib` annotation providing the data store and the library name:
    
    public class Main {
    
       @DatastoreLib(datastore # "couchdb", name "lightcouch")
       private static CouchDbClient couchDbClient;
    
       public static void main(String[] args) {
           List<Person> persons = couchDbClient.view("_all_docs")
                       .includeDocs(true)
                       .query(Person.class);
           ...
       }
    }

To add support for an external library, it is necessary to create a wrapper class used to instantiate the required class. Wrappers are simple classes implementing the
LibWrapper interface containing a single method. The method to implement gets an instance of the data store and needs to return an object of the library to use.

    
    public class LightCouchWrapper implements LibWrapper {
    
       @Override
       public Object getLib(Datastore datastore) {
           CouchDbProperties properties = new CouchDbProperties();
           properties.setDbName(datastore.getDataUnit());
           properties.setHost(datastore.getHost());
           properties.setPort(datastore.getPort());
           properties.setCreateDbIfNotExist(false);
           properties.setProtocol(DatastoreProperties.DEFAULT_PROTOCOL_TYPE.toString());
           return new CouchDbClient(properties);
       }
    }

## Hibernate Integration
One of the most useful features is the hibernate integration. In some cases, users maybe want to persists parts of an entity in a data store. The problem is, that 
this often requires a lot of additional code to persist and load objects in the data store and all situations of the entity life cycle need to be handled. To help 
developers with this task, a special hibernate integration was added to the framework.

To enable the data store integration in hibernate, the corresponding event listeners need to be configured and the `DataStoreModel` class needs to be added to 
the persistence unit:

    <persistence xmlns="http://java.sun.com/xml/ns/persistence"
                xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                xsi:schemaLocation="http://java.sun.com/xml/ns/persistence
                http://java.sun.com/xml/ns/persistence/persistence_2_0.xsd"
                version="2.0">
       <persistence-unit name="cloud" transaction-type="RESOURCE_LOCAL">
           <class>at.ac.tuwien.infosys.jcloudscale.datastore.hibernate.model.DatastoreModel</class>
           <class>at.ac.tuwien.infosys.jcloudscale.datastore.model.Article</class>
           <properties>
               <property name="hibernate.dialect" value="org.hibernate.dialect.PostgreSQLDialect"/>
               <property name="hibernate.connection.driver_class" value="org.postgresql.Driver" />
               <property name="hibernate.connection.url" value="jdbc:postgresql://192.168.56.101:5432/jcloudscale" />
               <property name="hibernate.connection.username" value="jcloudscale" />
               <property name="hibernate.connection.password" value="pass" />
               <property name="hibernate.show_sql" value="false" />
               <property name="hibernate.hbm2ddl.auto" value="create"/>
               <property name="hibernate.ejb.event.post-insert" value="at.ac.tuwien.infosys.jcloudscale.datastore.hibernate.DatastoreEventListener" />
               <property name="hibernate.ejb.event.post-load" value="at.ac.tuwien.infosys.jcloudscale.datastore.hibernate.DatastoreEventListener" />
               <property name="hibernate.ejb.event.post-update" value="at.ac.tuwien.infosys.jcloudscale.datastore.hibernate.DatastoreEventListener" />
              <property name="hibernate.ejb.event.post-delete" value="at.ac.tuwien.infosys.jcloudscale.datastore.hibernate.DatastoreEventListener" />
           </properties>
       </persistence-unit>
    </persistence>

A hibernate entity using the frameworks hibernate integration feature might look like this:
    
    @Entity
    public class Article {
    
       @Id
       @GeneratedValue
       private Long id;
    
       private String title;
    
       @Datastore("couchdb")
       @Transient
       private Person author;
    }

In this case, the author field will be persisted in the data store named `couchdb`. All operations necessary are executed automatically by the library when 
calling the corresponding hibernate method. To persist the information necessary to load the data store object, a special mapping table is used. Basically 
this information is used to get all objects in the data store for a given hibernate entity. To prevent hibernate from handling the author field it should 
be marked as transient.